Detecting_Harmful_Content
==============================

Abstract
------------

This project is related to the team project from the University Mannheim in the FSS22.

Harmful content is a challenging problem and widespread in today's online world. More and more of this content is appearing both in the context of websites and on social media. How far a multilingual text corpus crawled from the web contains this content will be explored in our paper. With the help of text mining methods, which analyze and semantically classify the texts of the web crawled OSCAR Corpus, the result of this publication is formed. State-of-the-art models of machine and deep learning covering the text classification domain will be tested and evaluated on different databases. Likewise, their applicability to unseen data from the OSCAR corpus is reviewed and presented. Also, a solution based on a mixture of Language Models and perplexity is tested and analyzed. It is the most promising approach, as it provides a realistic prediction of the harmful content in the OSCAR corpus.

Data & Models
------------
The Data and the Models used in this project can be found in the following link.

--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
